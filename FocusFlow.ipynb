{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NAA3Y_txaWbj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "789f67a9-d0a0-4bd9-8fdb-23df2bfc3eaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OZyLRus-cd8C"
      },
      "outputs": [],
      "source": [
        "!pip install python-dotenv -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3iqWMt4cx4S",
        "outputId": "602a150e-c3a5-4838-eeb6-e85fa6531a01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import google.generativeai as genai\n",
        "import dotenv\n",
        "import os\n",
        "dotenv.load_dotenv()\n",
        "api_key = os.getenv(\"API_KEY\")\n",
        "genai.configure(api_key=api_key)\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "def response(messages):\n",
        "  try:\n",
        "    response = model.generate_content(messages)\n",
        "    return response\n",
        "  except Exception as e:\n",
        "    return f\"Error: {str(e)}\"\n",
        "\n",
        "def fetch_conversation_history():\n",
        "  if \"messages\" not in st.session_state:\n",
        "    st.session_state[\"messages\"] = [\n",
        "        {\"role\": \"user\", \"parts\": \"System prompt: FocusFlow - You are a friendly and highly efficient AI productivity assistant. Greet the user warmly and ask how you can help with their productivity today. Based on their input, respond clearly and concisely with helpful suggestions, organized steps, or motivational tips. You can help with tasks like:– Creating or organizing to-do lists 📝– Planning a productive day or week 📅– Explaining productivity techniques (e.g., Pomodoro, time-blocking) ⏱– Offering quick summaries of productivity concepts 📊– Suggesting focus or habit-building strategies 💡Keep responses under 100 words. Use emojis to enhance clarity and keep the tone upbeat, focused, and supportive. Include links or visuals (YouTube/tutorials/images) if the user asks for examples. Always encourage users to take small, manageable steps.\"}\n",
        "    ]\n",
        "  return st.session_state[\"messages\"]\n",
        "st.title(\"FocusFlow - Personal AI Productivity Assistant\")\n",
        "user_input = st.chat_input(\"You: \")\n",
        "\n",
        "if user_input:\n",
        "  messages = fetch_conversation_history()\n",
        "  messages.append({\"role\": \"user\", \"parts\": user_input})\n",
        "  response = response(messages)\n",
        "  messages.append({\"role\": \"model\", \"parts\": response.candidates[0].content.parts[0].text})\n",
        "\n",
        "  for message in messages:\n",
        "    if message[\"role\"] == \"model\":\n",
        "      st.write(f\"FocusFlow: {message['parts']}\")\n",
        "    elif message[\"role\"] == \"user\" and \"System prompt\" not in message[\"parts\"]:\n",
        "      st.write(f\"You: {message['parts']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm00fCeSrjP4",
        "outputId": "6516badc-a5bd-470d-b528-dac1916a4841"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K\n",
            "added 22 packages in 2s\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl4FgMH2rpUA",
        "outputId": "141af614-1298-410a-c8ce-a7c816ab9dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.86.168.52\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py &>/content/logs.txt & curl ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDBpn4kTr7bN",
        "outputId": "e1ea6451-e566-4acc-c356-0e3a3d11feb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0Kyour url is: https://few-games-jam.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}